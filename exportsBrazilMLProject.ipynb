{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5285bd91",
   "metadata": {},
   "source": [
    "# Exportações Internacionais por Ano e Mês\n",
    "\n",
    "Descrição: Esta base de dados, carregada a partir do arquivo 'exportacao_full.csv', disponível em [Kaggle](https://www.kaggle.com/datasets/hugovallejo/brazil-exports), contém informações detalhadas sobre as exportações internacionais, organizadas por ano e mês. Ela inclui dados como o país de origem, cidade de origem, códigos e descrições de produtos, blocos econômicos, valores em dólares FOB e pesos líquidos das exportações. Os nomes das colunas foram mapeados de acordo com o dicionário de mapeamento fornecido, tornando-a pronta para análise e exploração de tendências nas exportações ao longo do tempo.\n",
    "\n",
    "Conforme conversado em sala de aula, para fins educacionais, a base de dados foi submetida a um script que apaga dados aleatóriamente o script está na pasta raíz do projeto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5d8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLOAD DATASET\n",
    "#!pip install kaggle\n",
    "#!kaggle datasets download -d hugovallejo/brazil-exports\n",
    "#!unzip brazil-exports.zip \n",
    "#!rm -rf brazil-exports.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11dc232b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Pais</th>\n",
       "      <th>Cidade</th>\n",
       "      <th>CodigoSH4</th>\n",
       "      <th>DescricaoSH4</th>\n",
       "      <th>CodigoSH2</th>\n",
       "      <th>DescricaoSH2</th>\n",
       "      <th>Blocoeconomico</th>\n",
       "      <th>ValorFOBUS</th>\n",
       "      <th>PesoLiquido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Itajaí - SC</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Meat and edible offal, of the poultry of headi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Meat and edible meat offal</td>\n",
       "      <td>Asia (minus MIDDLE EAST)</td>\n",
       "      <td>197162.0</td>\n",
       "      <td>99945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Lapa - PR</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Meat and edible offal, of the poultry of headi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Meat and edible meat offal</td>\n",
       "      <td>Asia (minus MIDDLE EAST)</td>\n",
       "      <td>114570.0</td>\n",
       "      <td>76989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Rolândia - PR</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Meat and edible offal, of the poultry of headi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Meat and edible meat offal</td>\n",
       "      <td>Asia (minus MIDDLE EAST)</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>São Paulo - SP</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Meat and edible offal, of the poultry of headi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Meat and edible meat offal</td>\n",
       "      <td>Asia (minus MIDDLE EAST)</td>\n",
       "      <td>153593.0</td>\n",
       "      <td>106541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Xaxim - SC</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Meat and edible offal, of the poultry of headi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Meat and edible meat offal</td>\n",
       "      <td>Asia (minus MIDDLE EAST)</td>\n",
       "      <td>26739.0</td>\n",
       "      <td>24990.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ano  Mes         Pais          Cidade  CodigoSH4  \\\n",
       "0  2010.0  1.0  Afghanistan     Itajaí - SC      207.0   \n",
       "1  2010.0  1.0  Afghanistan       Lapa - PR      207.0   \n",
       "2  2010.0  1.0  Afghanistan   Rolândia - PR      207.0   \n",
       "3  2010.0  1.0  Afghanistan  São Paulo - SP      207.0   \n",
       "4  2010.0  1.0  Afghanistan      Xaxim - SC      207.0   \n",
       "\n",
       "                                        DescricaoSH4  CodigoSH2  \\\n",
       "0  Meat and edible offal, of the poultry of headi...        2.0   \n",
       "1  Meat and edible offal, of the poultry of headi...        2.0   \n",
       "2  Meat and edible offal, of the poultry of headi...        2.0   \n",
       "3  Meat and edible offal, of the poultry of headi...        2.0   \n",
       "4  Meat and edible offal, of the poultry of headi...        2.0   \n",
       "\n",
       "                 DescricaoSH2            Blocoeconomico  ValorFOBUS  \\\n",
       "0  Meat and edible meat offal  Asia (minus MIDDLE EAST)    197162.0   \n",
       "1  Meat and edible meat offal  Asia (minus MIDDLE EAST)    114570.0   \n",
       "2  Meat and edible meat offal  Asia (minus MIDDLE EAST)     72900.0   \n",
       "3  Meat and edible meat offal  Asia (minus MIDDLE EAST)    153593.0   \n",
       "4  Meat and edible meat offal  Asia (minus MIDDLE EAST)     26739.0   \n",
       "\n",
       "   PesoLiquido  \n",
       "0      99945.0  \n",
       "1      76989.0  \n",
       "2      54000.0  \n",
       "3     106541.0  \n",
       "4      24990.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bibliotecas utilizadas\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#criando dataset a partir do arquivo csv\n",
    "\n",
    "data = pd.read_csv('exportacao_notfull.csv')\n",
    "column_names_mapping = {\n",
    "    'Year': 'Ano',\n",
    "    'Month': 'Mes',\n",
    "    'Country': 'Pais',\n",
    "    'City': 'Cidade',\n",
    "    'SH4 Code': 'CodigoSH4',\n",
    "    'SH4 Description': 'DescricaoSH4',\n",
    "    'SH2 Code': 'CodigoSH2',\n",
    "    'SH2 Description': 'DescricaoSH2',\n",
    "    'Economic Block': 'Blocoeconomico',\n",
    "    'US$ FOB': 'ValorFOBUS',\n",
    "    'Net Weight': 'PesoLiquido'\n",
    "}\n",
    "\n",
    "data.rename(columns=column_names_mapping, inplace=True)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976c065",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento\n",
    "### 1.1 Inicio do pré-processamento\n",
    "\n",
    "O DataFrame apresentado possui um total de 13.124.813 entradas e 11 colunas, com informações relacionadas a comércio internacional. As colunas incluem dados como ano, mês, país, cidade, códigos e descrições de produtos, bloco econômico, valor FOB em dólares e peso líquido. Foram identificados valores nulos em várias colunas, variando em quantidade, sendo a coluna \"PesoLiquido\" a que possui mais valores nulos, com 262.541 entradas faltantes. Não foram encontradas strings vazias em nenhuma coluna. Não foram identificados valores problemáticos. Após a remoção de duplicatas, o DataFrame reduziu para 13.123.569 entradas, mantendo a mesma estrutura de colunas e tipos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690456ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13124813 entries, 0 to 13124812\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   Ano             float64\n",
      " 1   Mes             float64\n",
      " 2   Pais            object \n",
      " 3   Cidade          object \n",
      " 4   CodigoSH4       float64\n",
      " 5   DescricaoSH4    object \n",
      " 6   CodigoSH2       float64\n",
      " 7   DescricaoSH2    object \n",
      " 8   Blocoeconomico  object \n",
      " 9   ValorFOBUS      float64\n",
      " 10  PesoLiquido     float64\n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "Quantidade de Valores Nulos em Cada Coluna: \n",
      "\n",
      "Ano               262289\n",
      "Mes               263059\n",
      "Pais              262063\n",
      "Cidade            262335\n",
      "CodigoSH4         263468\n",
      "DescricaoSH4      262255\n",
      "CodigoSH2         262325\n",
      "DescricaoSH2      263349\n",
      "Blocoeconomico    262071\n",
      "ValorFOBUS        262192\n",
      "PesoLiquido       262541\n",
      "dtype: int64\n",
      "\n",
      "Quantidade de Strings Vazias em Cada Coluna: \n",
      "\n",
      "Ano               0\n",
      "Mes               0\n",
      "Pais              0\n",
      "Cidade            0\n",
      "CodigoSH4         0\n",
      "DescricaoSH4      0\n",
      "CodigoSH2         0\n",
      "DescricaoSH2      0\n",
      "Blocoeconomico    0\n",
      "ValorFOBUS        0\n",
      "PesoLiquido       0\n",
      "dtype: int64\n",
      "\n",
      "Quantidade de Valores Problemáticos: \n",
      "\n",
      "0\n",
      "\n",
      "Resumo das Informações do DataFrame: \n",
      "\n",
      "None\n",
      "Linhas Duplicadas: \n",
      "             Ano   Mes      Pais                      Cidade  CodigoSH4  \\\n",
      "11321     2010.0   1.0   Belgium              Guarulhos - SP     8473.0   \n",
      "16152     2010.0   1.0   Bolivia               Sorocaba - SP     7315.0   \n",
      "20962     2010.0   1.0  Colombia               Campinas - SP     2924.0   \n",
      "21230     2010.0   1.0  Colombia          Caxias do Sul - RS     4009.0   \n",
      "24666     2010.0   1.0   Croatia                 Manaus - AM     9999.0   \n",
      "...          ...   ...       ...                         ...        ...   \n",
      "13087961  2013.0   NaN    Canada                Mossoró - RN      801.0   \n",
      "13096114  2013.0   NaN  Colombia                  Matão - SP     2005.0   \n",
      "13097216  2013.0  10.0  Colombia  São Bernardo do Campo - SP     8536.0   \n",
      "13107531  2013.0  10.0    France    São José dos Campos - SP     6806.0   \n",
      "13117659  2013.0   NaN   Jamaica           São Leopoldo - RS     7326.0   \n",
      "\n",
      "                                               DescricaoSH4  CodigoSH2  \\\n",
      "11321     Parts and accessories (other than covers, carr...       84.0   \n",
      "16152             Chain and parts thereof, of iron or steel       73.0   \n",
      "20962     Carboxyamide-function compounds; amide-functio...       29.0   \n",
      "21230     Tubes, pipes and hoses, of vulcanised rubber o...       40.0   \n",
      "24666     Consumption on board ships and aircraft (excep...       99.0   \n",
      "...                                                     ...        ...   \n",
      "13087961  Coconuts, Brazil nuts and cashew nuts, fresh o...        8.0   \n",
      "13096114  Other vegetables prepared or preserved otherwi...       20.0   \n",
      "13097216  Electrical apparatus for switching or protecti...       85.0   \n",
      "13107531  Slag wool, rock wool and similar mineral wools...       68.0   \n",
      "13117659                    Other articles of iron or steel       73.0   \n",
      "\n",
      "                                               DescricaoSH2  \\\n",
      "11321     Nuclear reactors, boilers, machinery and mecha...   \n",
      "16152                             Articles of iron or steel   \n",
      "20962                                     Organic chemicals   \n",
      "21230                           Rubber and articles thereof   \n",
      "24666                                    Special operations   \n",
      "...                                                     ...   \n",
      "13087961  Edible fruit and nuts; peel of citrus fruits o...   \n",
      "13096114  Preparations of vegetables, fruit, nuts or oth...   \n",
      "13097216  Electrical machinery and equipment and parts t...   \n",
      "13107531  Articles of stone, plaster, cement, asbestos, ...   \n",
      "13117659                          Articles of iron or steel   \n",
      "\n",
      "                         Blocoeconomico  ValorFOBUS  PesoLiquido  \n",
      "11321                               NaN     10110.0        112.0  \n",
      "16152                               NaN      9011.0        407.0  \n",
      "20962                               NaN      5808.0       2200.0  \n",
      "21230                               NaN      2126.0         65.0  \n",
      "24666                               NaN       400.0          0.0  \n",
      "...                                 ...         ...          ...  \n",
      "13087961                  North America    136912.0      15876.0  \n",
      "13096114                  South America     23616.0      11808.0  \n",
      "13097216                            NaN      5588.0         36.0  \n",
      "13107531                            NaN         1.0          0.0  \n",
      "13117659  Central America and Caribbean        13.0          0.0  \n",
      "\n",
      "[1244 rows x 11 columns]\n",
      "\n",
      " Estatísticas após Remoção de Duplicatas: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13123569 entries, 0 to 13124812\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   Ano             float64\n",
      " 1   Mes             float64\n",
      " 2   Pais            object \n",
      " 3   Cidade          object \n",
      " 4   CodigoSH4       float64\n",
      " 5   DescricaoSH4    object \n",
      " 6   CodigoSH2       float64\n",
      " 7   DescricaoSH2    object \n",
      " 8   Blocoeconomico  object \n",
      " 9   ValorFOBUS      float64\n",
      " 10  PesoLiquido     float64\n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 1.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Verifica a quantidade de valores nulos em cada coluna\n",
    "null_counts = data.isna().sum()\n",
    "\n",
    "# Verifica a quantidade de strings vazias em cada coluna\n",
    "empty_string_counts = (data == '').sum()\n",
    "\n",
    "# Verifica a quantidade de valores problemáticos \n",
    "negative_value_counts = (data['ValorFOBUS'] < 0).sum()  \n",
    "\n",
    "# Mostra um resumo das informações sobre o DataFrame\n",
    "data_info = data.info()\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"Quantidade de Valores Nulos em Cada Coluna: \\n\")\n",
    "print(null_counts)\n",
    "print(\"\\nQuantidade de Strings Vazias em Cada Coluna: \\n\")\n",
    "print(empty_string_counts)\n",
    "print(\"\\nQuantidade de Valores Problemáticos: \\n\")\n",
    "print(negative_value_counts)\n",
    "print(\"\\nResumo das Informações do DataFrame: \\n\")\n",
    "print(data_info)\n",
    "\n",
    "# Verifica linhas duplicadas com base em todas as colunas\n",
    "duplicates = data[data.duplicated()]\n",
    "\n",
    "# Remove linhas duplicadas (mantém a primeira ocorrência)\n",
    "data_no_duplicates = data.drop_duplicates()\n",
    "\n",
    "# Exibe as linhas duplicadas\n",
    "print(\"Linhas Duplicadas: \")\n",
    "print(duplicates)\n",
    "\n",
    "# Exibe as estatísticas após a remoção de duplicatas\n",
    "print(\"\\n Estatísticas após Remoção de Duplicatas: \\n\")\n",
    "print(data_no_duplicates.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faeeb0a",
   "metadata": {},
   "source": [
    "### 1.2 Verificar dados faltantes\n",
    "\n",
    "Para esse trabalho escolheremos aquele país com a maior quantidade de dados faltantes e focaremos as análises nele. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbbe4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pais\n",
      "Argentina                    260646\n",
      "Paraguay                     247256\n",
      "Uruguay                      171342\n",
      "Bolivia                      153404\n",
      "Colombia                     136500\n",
      "                              ...  \n",
      "Western Sahara                    1\n",
      "Christmas Island                  1\n",
      "Cocos (Keeling) Islands           1\n",
      "Saint Pierre and Miquelon         1\n",
      "Wake Island                       0\n",
      "Length: 250, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calcula o número de valores ausentes por país\n",
    "dados_faltantes_por_pais = data.groupby(\"Pais\").apply(lambda x: x.isna().sum())\n",
    "\n",
    "# Soma o número total de valores ausentes por país\n",
    "total_dados_faltantes_por_pais = dados_faltantes_por_pais.sum(axis=1)\n",
    "\n",
    "# Classifica os países pelo total de dados faltantes em ordem decrescente\n",
    "paises_com_mais_dados_faltantes = total_dados_faltantes_por_pais.sort_values(ascending=False)\n",
    "\n",
    "# Exibe os países com mais dados faltantes e a quantidade de dados faltantes por país\n",
    "print(paises_com_mais_dados_faltantes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f2f9a",
   "metadata": {},
   "source": [
    "## 1.3 Inicio da preparação dos dados - Argentina \n",
    "\n",
    "Selecionamos a Argentina como foco de nossa análise devido ao maior número de problemas de integridade dos dados em seu conjunto. Essa escolha visa facilitar o entendimento didático. Conforme revelado pelos resultados, o total de entradas no conjunto de dados para a Argentina é de 1.299.852 registros. Dessas, 1.061.396 são consideradas completas, ou seja, não apresentam valores ausentes.\n",
    "\n",
    "Esses números indicam que a grande maioria das entradas contém informações completas e confiáveis. No entanto, ainda há uma parcela significativa de registros com valores ausentes, sugerindo a necessidade de ações adicionais, como o preenchimento dessas lacunas ou a realização de tratamentos específicos para melhorar a qualidade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d97c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodigoSH4         26447\n",
      "Mes               26350\n",
      "DescricaoSH2      26216\n",
      "DescricaoSH4      26086\n",
      "CodigoSH2         26035\n",
      "PesoLiquido       25998\n",
      "Blocoeconomico    25930\n",
      "ValorFOBUS        25884\n",
      "Cidade            25861\n",
      "Ano               25839\n",
      "Pais                  0\n",
      "dtype: int64\n",
      "Número de linhas para a Argentina: 1299852\n",
      "Número de linhas completas para a Argentina: 1061396\n"
     ]
    }
   ],
   "source": [
    "# Crie um novo DataFrame com as linhas que atendem à condição desejada\n",
    "new_df_argentina = data[data['Pais'] == 'Argentina'].copy()\n",
    "\n",
    "# Filtra o DataFrame para incluir apenas as linhas correspondentes à Argentina\n",
    "\n",
    "new_df_argentina = data[data['Pais'] == 'Argentina']\n",
    "\n",
    "# Calcula o número de valores ausentes em cada coluna para a Argentina\n",
    "dados_faltantes_por_coluna = new_df_argentina.isna().sum()\n",
    "\n",
    "# Classifica as colunas pelo total de dados faltantes em ordem decrescente\n",
    "colunas_com_mais_dados_faltantes = dados_faltantes_por_coluna.sort_values(ascending=False)\n",
    "\n",
    "# Exibe as colunas com mais dados faltantes e a quantidade de dados faltantes por coluna\n",
    "print(colunas_com_mais_dados_faltantes)\n",
    "\n",
    "\n",
    "# Conta o número de linhas para o país \"Argentina\"\n",
    "numero_de_linhas_argentina = new_df_argentina.shape[0]\n",
    "\n",
    "# Exibe o número de linhas para o país \"Argentina\"\n",
    "print(\"Número de linhas para a Argentina:\", numero_de_linhas_argentina)\n",
    "\n",
    "# Conta as linhas completas para a Argentina\n",
    "linhas_completas_argentina = (new_df_argentina.count(axis=1) == len(new_df_argentina.columns)).sum()\n",
    "\n",
    "# Exibe o número de linhas completas para a Argentina\n",
    "print(\"Número de linhas completas para a Argentina:\", linhas_completas_argentina)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b323f",
   "metadata": {},
   "source": [
    "## 1.4 Preenchimento de Dados Ausentes\n",
    "\n",
    "Nesta etapa, começaremos transferindo os dados do país para um novo DataFrame, onde realizaremos os procedimentos de tratamento. Este conjunto de dados compreende quatro tipos de informações inter-relacionadas: os códigos SH2 e SH4 estão associados às suas respetivas descrições, sendo provado abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34945b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não existem códigos SH2 ou SH4 com múltiplas descrições.\n"
     ]
    }
   ],
   "source": [
    "# Criar uma cópia do DataFrame para a Argentina\n",
    "#new_df_argentina = data[data['Pais'] == 'Argentina'].copy()\n",
    "\n",
    "# Verificar se há várias descrições para o mesmo código SH2\n",
    "duplicados_sh2 = new_df_argentina.groupby('CodigoSH2')['DescricaoSH2'].nunique() > 1\n",
    "\n",
    "# Verificar se há várias descrições para o mesmo código SH4\n",
    "duplicados_sh4 = new_df_argentina.groupby('CodigoSH4')['DescricaoSH4'].nunique() > 1\n",
    "\n",
    "\n",
    "if duplicados_sh2.any() or duplicados_sh4.any():\n",
    "    print(\"Existem códigos SH2 ou SH4 com múltiplas descrições.\")\n",
    "else:\n",
    "    print(\"Não existem códigos SH2 ou SH4 com múltiplas descrições.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cd6eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/pz8nvy810xjdk3ywmvl5_0wr0000gn/T/ipykernel_52266/3578566918.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df_argentina['CodigoSH2'] = new_df_argentina.apply(\n",
      "/var/folders/fm/pz8nvy810xjdk3ywmvl5_0wr0000gn/T/ipykernel_52266/3578566918.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df_argentina['DescricaoSH2'] = new_df_argentina.apply(\n"
     ]
    }
   ],
   "source": [
    "# Função para preencher valores ausentes em 'CodigoSH2' com base em 'DescricaoSH2' e vice-versa\n",
    "def fill_missing_values(row, column_to_fill, matching_column):\n",
    "    if pd.isna(row[column_to_fill]) and not pd.isna(row[matching_column]):\n",
    "        matching_value = new_df_argentina.loc[\n",
    "            (new_df_argentina[matching_column] == row[matching_column]) &\n",
    "            (~pd.isna(new_df_argentina[column_to_fill]))\n",
    "        ]\n",
    "        if not matching_value.empty:\n",
    "            return matching_value.iloc[0][column_to_fill]\n",
    "    return row[column_to_fill]\n",
    "\n",
    "# Aplicar a função às colunas 'CodigoSH2' e 'DescricaoSH2'\n",
    "new_df_argentina['CodigoSH2'] = new_df_argentina.apply(\n",
    "    lambda row: fill_missing_values(row, 'CodigoSH2', 'DescricaoSH2'), axis=1)\n",
    "\n",
    "new_df_argentina['DescricaoSH2'] = new_df_argentina.apply(\n",
    "    lambda row: fill_missing_values(row, 'DescricaoSH2', 'CodigoSH2'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f4b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/pz8nvy810xjdk3ywmvl5_0wr0000gn/T/ipykernel_52266/3785229030.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df_argentina['CodigoSH4'] = new_df_argentina.apply(\n",
      "/var/folders/fm/pz8nvy810xjdk3ywmvl5_0wr0000gn/T/ipykernel_52266/3785229030.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df_argentina['DescricaoSH4'] = new_df_argentina.apply(\n"
     ]
    }
   ],
   "source": [
    "# Função para preencher valores ausentes em 'CodigoSH4' com base em 'DescricaoSH4' e vice-versa\n",
    "def fill_missing_values(row, column_to_fill, matching_column):\n",
    "    if pd.isna(row[column_to_fill]) and not pd.isna(row[matching_column]):\n",
    "        matching_value = new_df_argentina.loc[\n",
    "            (new_df_argentina[matching_column] == row[matching_column]) &\n",
    "            (~pd.isna(new_df_argentina[column_to_fill]))\n",
    "        ]\n",
    "        if not matching_value.empty:\n",
    "            return matching_value.iloc[0][column_to_fill]\n",
    "    return row[column_to_fill]\n",
    "\n",
    "# Aplicar a função às colunas 'CodigoSH4' e 'DescricaoSH4'\n",
    "new_df_argentina['CodigoSH4'] = new_df_argentina.apply(\n",
    "    lambda row: fill_missing_values(row, 'CodigoSH4', 'DescricaoSH4'), axis=1)\n",
    "\n",
    "new_df_argentina['DescricaoSH4'] = new_df_argentina.apply(\n",
    "    lambda row: fill_missing_values(row, 'DescricaoSH4', 'CodigoSH4'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7edfcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ano               25839\n",
       "Mes               26350\n",
       "Pais                  0\n",
       "Cidade            25861\n",
       "CodigoSH4           557\n",
       "DescricaoSH4        557\n",
       "CodigoSH2           528\n",
       "DescricaoSH2        528\n",
       "Blocoeconomico    25930\n",
       "ValorFOBUS        25884\n",
       "PesoLiquido       25998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma cópia do DataFrame para a Argentina\n",
    "#new_df_argentina.to_csv('new_df_argentina.csv', index=False)\n",
    "new_df_argentina = pd.read_csv('new_df_argentina.csv')\n",
    "\n",
    "# Calcula o número de valores ausentes em cada coluna para a Argentina\n",
    "dados_faltantes_por_coluna = new_df_argentina.isna().sum()\n",
    "dados_faltantes_por_coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9a6af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma cópia do DataFrame para a Argentina\n",
    "cp_df_argentina = new_df_argentina.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451b7c6",
   "metadata": {},
   "source": [
    "Agora, criamos uma nova coluna no DataFrame chamada 'CodigoSH2_Cidade', que combina os valores das colunas 'CodigoSH2', 'Cidade' e 'Blocoeconomico' usando o caractere de sublinhado \"_\" como separador.\n",
    "\n",
    "Em seguida, calculamos a média do peso (coluna 'PesoLiquido') para cada valor único na coluna 'CodigoSH2_Cidade' usando o método 'groupby'. Isso significa que estamos obtendo a média do peso para cada combinação única de 'CodigoSH2' e 'Cidade'.\n",
    "\n",
    "Depois, preenchemos os valores ausentes na coluna 'PesoLiquido'. Para fazer isso, usamos uma função lambda que verifica se o valor na coluna 'CodigoSH2_Cidade' não é nulo (não é um valor NaN) e, se não for nulo, substituímos o valor na coluna 'PesoLiquido' pelo valor médio correspondente à 'CodigoSH2_Cidade'. Isso ajuda a preencher os valores ausentes na coluna de peso com base nas médias correspondentes.\n",
    "\n",
    "Em seguida, calculamos dois totais para cada 'CodigoSH2_Cidade': o total da coluna 'ValorFOBUS' e o total da coluna 'PesoLiquido'. Isso é feito usando o método 'agg' para agregar os valores de acordo com 'CodigoSH2_Cidade'.\n",
    "\n",
    "Depois, calculamos o valor unitário específico para cada 'CodigoSH2_Cidade'. Isso significa dividir o total da coluna 'ValorFOBUS' pelo total da coluna 'PesoLiquido' e armazenar o resultado na nova coluna 'ValorUnitario'.\n",
    "\n",
    "Em seguida, preenchemos os valores ausentes na coluna 'ValorFOBUS'. Para fazer isso, usamos o método 'fillna' com base no mapeamento dos valores unitários específicos obtidos anteriormente usando 'CodigoSH2_Cidade'.\n",
    "\n",
    "Por fim, multiplicamos o valor da coluna 'ValorFOBUS' pelo valor da coluna 'PesoLiquido' quando o valor em 'ValorFOBUS' é nulo (NaN) e o valor em 'PesoLiquido' não é nulo. Isso pode ser uma etapa para preencher ou ajustar os valores em 'ValorFOBUS' com base nos pesos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "196fa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not new_df_argentina['CodigoSH2'].isnull().all():\n",
    "    # Converter os valores de 'CodigoSH2' para string\n",
    "    new_df_argentina['CodigoSH2'] = new_df_argentina['CodigoSH2'].astype(str)\n",
    "    \n",
    "    # Criar uma coluna que combine 'CodigoSH2', 'Cidade' e 'Blocoeconomico'\n",
    "    new_df_argentina['CodigoSH2_Cidade'] = new_df_argentina['CodigoSH2'] + '_' + new_df_argentina['Cidade'] + '_' + new_df_argentina['Blocoeconomico']\n",
    "\n",
    "    # Restaurar o tipo original de 'CodigoSH2'\n",
    "    new_df_argentina['CodigoSH2'] = new_df_argentina['CodigoSH2'].astype(float)\n",
    "\n",
    "    # Calcular a média do peso para cada 'CodigoSH2_Cidade_Blocoeconomico'\n",
    "    media_peso_por_codigo_sh2_cidade = new_df_argentina.groupby('CodigoSH2_Cidade')['PesoLiquido'].mean()\n",
    "\n",
    "    # Preencher os valores ausentes na coluna 'PesoLiquido' com base na média correspondente a 'CodigoSH2_Cidade'\n",
    "    new_df_argentina['PesoLiquido'] = new_df_argentina.apply(\n",
    "        lambda row: media_peso_por_codigo_sh2_cidade[row['CodigoSH2_Cidade']] if not pd.isna(row['CodigoSH2_Cidade']) else row['PesoLiquido'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calcular o total ValorFOBUS e o total PesoLiquido para cada 'CodigoSH2_Cidade'\n",
    "    totals_por_codigo_sh2_cidade = new_df_argentina.groupby('CodigoSH2_Cidade').agg({'ValorFOBUS': 'sum', 'PesoLiquido': 'sum'})\n",
    "\n",
    "    # Calcular o valor unitário específico para cada 'CodigoSH2_Cidade'\n",
    "    totals_por_codigo_sh2_cidade['ValorUnitario'] = totals_por_codigo_sh2_cidade['ValorFOBUS'] / totals_por_codigo_sh2_cidade['PesoLiquido']\n",
    "\n",
    "    # Preencher os valores ausentes na coluna 'ValorFOBUS' com base no valor unitário específico para cada 'CodigoSH2_Cidade'\n",
    "    new_df_argentina['ValorFOBUS'] = new_df_argentina['ValorFOBUS'].fillna(\n",
    "        new_df_argentina['CodigoSH2_Cidade'].map(totals_por_codigo_sh2_cidade['ValorUnitario'])\n",
    "    )\n",
    "\n",
    "    # Multiplicar 'ValorFOBUS' por nulo e PesoLiquido não nulo\n",
    "    new_df_argentina['ValorFOBUS'] = new_df_argentina.apply(\n",
    "        lambda row: row['ValorFOBUS'] * row['PesoLiquido'] if pd.isnull(row['ValorFOBUS']) and not pd.isnull(row['PesoLiquido']) else row['ValorFOBUS'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Remover a coluna temporária 'CodigoSH2_Cidade'\n",
    "    new_df_argentina.drop(columns=['CodigoSH2_Cidade'], inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "861e9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not new_df_argentina['CodigoSH4'].isnull().all():\n",
    "    # Converter os valores de 'CodigoSH4' para string\n",
    "    new_df_argentina['CodigoSH4'] = new_df_argentina['CodigoSH4'].astype(str)\n",
    "    \n",
    "    # Criar uma coluna que combine 'CodigoSH4', 'Cidade' e 'Blocoeconomico'\n",
    "    new_df_argentina['CodigoSH4_Cidade'] = new_df_argentina['CodigoSH4'] + '_' + new_df_argentina['Cidade'] + '_' + new_df_argentina['Blocoeconomico']\n",
    "\n",
    "    # Restaurar o tipo original de 'CodigoSH4'\n",
    "    new_df_argentina['CodigoSH4'] = new_df_argentina['CodigoSH4'].astype(float)\n",
    "\n",
    "    # Calcular a média do peso para cada 'CodigoSH4_Cidade_Blocoeconomico'\n",
    "    media_peso_por_codigo_sh4_cidade = new_df_argentina.groupby('CodigoSH4_Cidade')['PesoLiquido'].mean()\n",
    "\n",
    "    # Preencher os valores ausentes na coluna 'PesoLiquido' com base na média correspondente a 'CodigoSH4_Cidade'\n",
    "    new_df_argentina['PesoLiquido'] = new_df_argentina.apply(\n",
    "        lambda row: media_peso_por_codigo_sh4_cidade[row['CodigoSH4_Cidade']] if not pd.isna(row['CodigoSH4_Cidade']) else row['PesoLiquido'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calcular o total ValorFOBUS e o total PesoLiquido para cada 'CodigoSH4_Cidade'\n",
    "    totals_por_codigo_sh4_cidade = new_df_argentina.groupby('CodigoSH4_Cidade').agg({'ValorFOBUS': 'sum', 'PesoLiquido': 'sum'})\n",
    "\n",
    "    # Calcular o valor unitário específico para cada 'CodigoSH4_Cidade'\n",
    "    totals_por_codigo_sh4_cidade['ValorUnitario'] = totals_por_codigo_sh4_cidade['ValorFOBUS'] / totals_por_codigo_sh4_cidade['PesoLiquido']\n",
    "\n",
    "    # Preencher os valores ausentes na coluna 'ValorFOBUS' com base no valor unitário específico para cada 'CodigoSH4_Cidade'\n",
    "    new_df_argentina['ValorFOBUS'] = new_df_argentina['ValorFOBUS'].fillna(\n",
    "        new_df_argentina['CodigoSH4_Cidade'].map(totals_por_codigo_sh4_cidade['ValorUnitario'])\n",
    "    )\n",
    "\n",
    "    # Multiplicar 'ValorFOBUS' por nulo e PesoLiquido não nulo\n",
    "    new_df_argentina['ValorFOBUS'] = new_df_argentina.apply(\n",
    "        lambda row: row['ValorFOBUS'] * row['PesoLiquido'] if pd.isnull(row['ValorFOBUS']) and not pd.isnull(row['PesoLiquido']) else row['ValorFOBUS'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Remover a coluna temporária 'CodigoSH4_Cidade'\n",
    "    new_df_argentina.drop(columns=['CodigoSH4_Cidade'], inplace=True)\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f65ac3",
   "metadata": {},
   "source": [
    "Como nas proximas tratativas usaremos os códigos SH2 ou SH4 excluíremos as linhas que não tem, pois não nos servirá. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f118950d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ano               0\n",
       "Mes               0\n",
       "Pais              0\n",
       "Cidade            0\n",
       "CodigoSH4         0\n",
       "DescricaoSH4      0\n",
       "CodigoSH2         0\n",
       "DescricaoSH2      0\n",
       "Blocoeconomico    0\n",
       "ValorFOBUS        0\n",
       "PesoLiquido       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remover linhas sem valores \n",
    "new_df_argentina.dropna(subset=['CodigoSH2'], how='all', inplace=True)\n",
    "new_df_argentina.dropna(subset=['CodigoSH4'], how='all', inplace=True)\n",
    "new_df_argentina.dropna(subset=['ValorFOBUS'], how='all', inplace=True)\n",
    "new_df_argentina.dropna(subset=['PesoLiquido'], how='all', inplace=True)\n",
    "\n",
    "\n",
    "# Calcula o número de valores ausentes em cada coluna para a Argentina\n",
    "dados_faltantes_por_coluna = new_df_argentina.isna().sum()\n",
    "dados_faltantes_por_coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df3f0196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296648 entries, 0 to 1299851\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Ano             1270867 non-null  float64\n",
      " 1   Mes             1270376 non-null  float64\n",
      " 2   Pais            1296648 non-null  object \n",
      " 3   Cidade          1271814 non-null  object \n",
      " 4   CodigoSH4       1296648 non-null  float64\n",
      " 5   DescricaoSH4    1296648 non-null  object \n",
      " 6   CodigoSH2       1296648 non-null  float64\n",
      " 7   DescricaoSH2    1296648 non-null  object \n",
      " 8   Blocoeconomico  1271769 non-null  object \n",
      " 9   ValorFOBUS      1296648 non-null  float64\n",
      " 10  PesoLiquido     1296648 non-null  float64\n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 118.7+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df_argentina.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "968ca77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Carregar o DataFrame\n",
    "df = new_df_argentina\n",
    "\n",
    "# Lidar com os valores ausentes\n",
    "df['Ano'].fillna(1900, inplace=True)  # Substitua 0 pelo valor desejado\n",
    "df['Mes'].fillna(99, inplace=True)  # Substitua 0 pelo valor desejado\n",
    "df['Cidade'].fillna('Desconhecido', inplace=True)  # Substitua 'Desconhecido' pelo valor desejado\n",
    "df['Blocoeconomico'].fillna('Desconhecido', inplace=True)  # Substitua 'Desconhecido' pelo valor desejado\n",
    "\n",
    "# # Converter a coluna Blocoeconomico em representações numéricas com one-hot encoding\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['Blocoeconomico'])\n",
    "\n",
    "# # Converta a coluna Cidade em valores numéricos usando LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['Cidade'] = label_encoder.fit_transform(df['Cidade'])\n",
    "\n",
    "# # Separar os dados em recursos (X) e rótulos (y)\n",
    "# X = df[['CodigoSH2', 'ValorFOBUS', 'PesoLiquido'] + list(df.columns[11:])].values\n",
    "# y = df['Cidade'].values\n",
    "\n",
    "# # Inicializar o modelo XGBoost\n",
    "# model = XGBClassifier()\n",
    "\n",
    "# # Definir uma estratificação usando StratifiedKFold\n",
    "# stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Realizar a validação cruzada com estratificação\n",
    "# cv_scores = cross_val_score(model, X, y, cv=stratified_kfold, error_score='raise')\n",
    "\n",
    "# # Exibir as pontuações da validação cruzada\n",
    "# print(\"Pontuações da validação cruzada:\", cv_scores)\n",
    "# print(\"Acurácia média da validação cruzada:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83fd70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_df_argentina_limpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be75d2",
   "metadata": {},
   "source": [
    "Devido ao erro persistente nas classes entre nosso conjunto de treinamento e validação cruzada, optamos por realizar uma análise descritiva abrangente dos dados. Isso nos permitirá identificar as classes que podem ser retiradas do conjunto de dados ou agrupadas, a fim de resolver o problema de discrepância de classes e, ao mesmo tempo, garantir que nossas análises subsequentes sejam confiáveis. Estamos comprometidos em garantir a qualidade dos resultados e a integridade dos dados em nosso processo de modelagem de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336012f",
   "metadata": {},
   "source": [
    "### 2 Análise descritiva dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bbdc458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ano                  0\n",
       "Mes                  0\n",
       "Pais                 0\n",
       "Cidade               0\n",
       "CodigoSH4          557\n",
       "DescricaoSH4       557\n",
       "CodigoSH2          528\n",
       "DescricaoSH2       528\n",
       "Blocoeconomico       0\n",
       "ValorFOBUS         983\n",
       "PesoLiquido       1159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_argentina = pd.read_csv('new_df_argentina_limpo.csv')\n",
    "dados_faltantes_por_coluna = new_df_argentina.isna().sum()\n",
    "dados_faltantes_por_coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb5a94fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Pais</th>\n",
       "      <th>Cidade</th>\n",
       "      <th>CodigoSH4</th>\n",
       "      <th>DescricaoSH4</th>\n",
       "      <th>CodigoSH2</th>\n",
       "      <th>DescricaoSH2</th>\n",
       "      <th>Blocoeconomico</th>\n",
       "      <th>ValorFOBUS</th>\n",
       "      <th>PesoLiquido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Alfenas - MG</td>\n",
       "      <td>901.0</td>\n",
       "      <td>Coffee, whether or not roasted or decaffeinate...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Coffee, tea, maté and spices</td>\n",
       "      <td>South America</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>149069.825059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Alfenas - MG</td>\n",
       "      <td>901.0</td>\n",
       "      <td>Coffee, whether or not roasted or decaffeinate...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Coffee, tea, maté and spices</td>\n",
       "      <td>Southern Common Market (MERCOSUL)</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>155204.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Almirante Tamandaré - PR</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>Floor coverings of plastics, whether or not se...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Plastics and articles thereof</td>\n",
       "      <td>South America</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>6036.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Almirante Tamandaré - PR</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>Floor coverings of plastics, whether or not se...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Plastics and articles thereof</td>\n",
       "      <td>Southern Common Market (MERCOSUL)</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>5887.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Almirante Tamandaré - PR</td>\n",
       "      <td>8466.0</td>\n",
       "      <td>Parts and accessories suitable for use solely ...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Nuclear reactors, boilers, machinery and mecha...</td>\n",
       "      <td>South America</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3358.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ano  Mes       Pais                    Cidade  CodigoSH4  \\\n",
       "0  2010.0  1.0  Argentina              Alfenas - MG      901.0   \n",
       "1  1900.0  1.0  Argentina              Alfenas - MG      901.0   \n",
       "2  2010.0  1.0  Argentina  Almirante Tamandaré - PR     3918.0   \n",
       "3  2010.0  1.0  Argentina  Almirante Tamandaré - PR     3918.0   \n",
       "4  2010.0  1.0  Argentina  Almirante Tamandaré - PR     8466.0   \n",
       "\n",
       "                                        DescricaoSH4  CodigoSH2  \\\n",
       "0  Coffee, whether or not roasted or decaffeinate...        9.0   \n",
       "1  Coffee, whether or not roasted or decaffeinate...        9.0   \n",
       "2  Floor coverings of plastics, whether or not se...       39.0   \n",
       "3  Floor coverings of plastics, whether or not se...       39.0   \n",
       "4  Parts and accessories suitable for use solely ...       84.0   \n",
       "\n",
       "                                        DescricaoSH2  \\\n",
       "0                       Coffee, tea, maté and spices   \n",
       "1                       Coffee, tea, maté and spices   \n",
       "2                      Plastics and articles thereof   \n",
       "3                      Plastics and articles thereof   \n",
       "4  Nuclear reactors, boilers, machinery and mecha...   \n",
       "\n",
       "                      Blocoeconomico  ValorFOBUS    PesoLiquido  \n",
       "0                      South America     56000.0  149069.825059  \n",
       "1  Southern Common Market (MERCOSUL)     56000.0  155204.897959  \n",
       "2                      South America      4277.0    6036.342105  \n",
       "3  Southern Common Market (MERCOSUL)      4277.0    5887.432432  \n",
       "4                      South America       250.0    3358.200000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_argentina.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb272b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
